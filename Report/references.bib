
@article{dravins_optical_2013,
	title = {Optical intensity interferometry with the Cherenkov Telescope Array},
	volume = {43},
	issn = {0927-6505},
	url = {https://www.sciencedirect.com/science/article/pii/S0927650512001314},
	doi = {10.1016/j.astropartphys.2012.04.017},
	series = {Seeing the High-Energy Universe with the Cherenkov Telescope Array - The Science Explored with the {CTA}},
	abstract = {With its unprecedented light-collecting area for night-sky observations, the Cherenkov Telescope Array ({CTA}) holds great potential for also optical stellar astronomy, in particular as a multi-element intensity interferometer for realizing imaging with sub-milliarcsecond angular resolution. Such an order-of-magnitude increase of the spatial resolution achieved in optical astronomy will reveal the surfaces of rotationally flattened stars with structures in their circumstellar disks and winds, or the gas flows between close binaries. Image reconstruction is feasible from the second-order coherence of light, measured as the temporal correlations of arrival times between photons recorded in different telescopes. This technique (once pioneered by Hanbury Brown and Twiss) connects telescopes only with electronic signals and is practically insensitive to atmospheric turbulence and to imperfections in telescope optics. Detector and telescope requirements are very similar to those for imaging air Cherenkov observatories, the main difference being the signal processing (calculating cross correlations between single camera pixels in pairs of telescopes). Observations of brighter stars are not limited by sky brightness, permitting efficient {CTA} use during also bright-Moon periods. While other concepts have been proposed to realize kilometer-scale optical interferometers of conventional amplitude (phase-) type, both in space and on the ground, their complexity places them much further into the future than {CTA}, which thus could become the first kilometer-scale optical imager in astronomy.},
	pages = {331--347},
	journaltitle = {Astroparticle Physics},
	shortjournal = {Astroparticle Physics},
	author = {Dravins, Dainis and {LeBohec}, Stephan and Jensen, Hannes and Nuñez, Paul D.},
	urldate = {2023-09-19},
	date = {2013-03-01},
	keywords = {Cherenkov telescopes, Hanbury Brown–Twiss, Intensity interferometry, Optical interferometry, Photon statistics, Stars: individual},
}

@article{abdalla_sensitivity_2021,
	title = {Sensitivity of the Cherenkov Telescope Array for probing cosmology and fundamental physics with gamma-ray propagation},
	volume = {2021},
	issn = {1475-7516},
	url = {https://dx.doi.org/10.1088/1475-7516/2021/02/048},
	doi = {10.1088/1475-7516/2021/02/048},
	abstract = {The Cherenkov Telescope Array ({CTA}), the new-generation ground-based observatory for γ astronomy, provides unique capabilities to address significant open questions in astrophysics, cosmology, and fundamental physics. We study some of the salient areas of γ cosmology that can be explored as part of the Key Science Projects of {CTA}, through simulated observations of active galactic nuclei ({AGN}) and of their relativistic jets. Observations of {AGN} with {CTA} will enable a measurement of γ absorption on the extragalactic background light with a statistical uncertainty below 15\% up to a redshift z=2 and to constrain or detect γ halos up to intergalactic-magnetic-field strengths of at least 0.3 {pG} . Extragalactic observations with {CTA} also show promising potential to probe physics beyond the Standard Model. The best limits on Lorentz invariance violation from γ astronomy will be improved by a factor of at least two to three. {CTA} will also probe the parameter space in which axion-like particles could constitute a significant fraction, if not all, of dark matter. We conclude on the synergies between {CTA} and other upcoming facilities that will foster the growth of γ cosmology.},
	pages = {048},
	number = {2},
	journaltitle = {Journal of Cosmology and Astroparticle Physics},
	shortjournal = {J. Cosmol. Astropart. Phys.},
	author = {Abdalla, H. and Abe, H. and Acero, F. and Acharyya, A. and Adam, R. and Agudo, I. and Aguirre-Santaella, A. and Alfaro, R. and Alfaro, J. and Alispach, C. and Aloisio, R. and Batista, R. Alves and Amati, L. and Amato, E. and Ambrosi, G. and Angüner, E. O. and Araudo, A. and Armstrong, T. and Arqueros, F. and Arrabito, L. and Asano, K. and Ascasíbar, Y. and Ashley, M. and Backes, M. and Balazs, C. and Balbo, M. and Balmaverde, B. and Larriva, A. Baquero and Martins, V. Barbosa and Barkov, M. and Baroncelli, L. and Almeida, U. Barres de and Barrio, J. A. and Batista, P.-I. and González, J. Becerra and Becherini, Y. and Beck, G. and Tjus, J. Becker and Belmont, R. and Benbow, W. and Bernardini, E. and Berti, A. and Berton, M. and Bertucci, B. and Beshley, V. and Bi, B. and Biasuzzi, B. and Biland, A. and Bissaldi, E. and Biteau, J. and Blanch, O. and Bocchino, F. and Boisson, C. and Bolmont, J. and Bonanno, G. and Arbeletche, L. Bonneau and Bonnoli, G. and Bordas, P. and Bottacini, E. and Böttcher, M. and Bozhilov, V. and Bregeon, J. and Brill, A. and Brown, A. M. and Bruno, P. and Bruno, A. and Bulgarelli, A. and Burton, M. and Buscemi, M. and Caccianiga, A. and Cameron, R. and Capasso, M. and Caprai, M. and Caproni, A. and Capuzzo-Dolcetta, R. and Caraveo, P. and Carosi, R. and Carosi, A. and Casanova, S. and Cascone, E. and Cauz, D. and Cerny, K. and Cerruti, M. and Chadwick, P. and Chaty, S. and Chen, A. and Chernyakova, M. and Chiaro, G. and Chiavassa, A. and Chytka, L. and Conforti, V. and Conte, F. and Contreras, J. L. and Coronado-Blazquez, J. and Cortina, J. and Costa, A. and Costantini, H. and Covino, S. and Cristofari, P. and Cuevas, O. and D'Ammando, F. and Daniel, M. K. and Davies, J. and Dazzi, F. and Angelis, A. De and Lavergne, M. de Bony de and Caprio, V. De and Anjos, R. de Cássia dos and Pino, E. M. de Gouveia Dal and Lotto, B. De and Martino, D. De and Naurois, M. de and Wilhelmi, E. de Oña and Palma, F. De and Souza, V. de and Delgado, C. and Ceca, R. Della and Volpe, D. della and Depaoli, D. and Girolamo, T. Di and Pierro, F. Di and Díaz, C. and Díaz-Bahamondes, C. and Diebold, S. and Djannati-Ataï, A. and Dmytriiev, A. and Domínguez, A. and Donini, A. and Dorner, D. and Doro, M. and Dournaux, J. and Dwarkadas, V. V. and Ebr, J. and Eckner, C. and Einecke, S. and Ekoume, T. R. N. and Elsässer, D. and Emery, G. and Evoli, C. and Fairbairn, M. and Falceta-Goncalves, D. and Fegan, S. and Feng, Q. and Ferrand, G. and Fiandrini, E. and Fiasson, A. and Fioretti, V. and Foffano, L. and Fonseca, M. V. and Font, L. and Fontaine, G. and Franco, F. J. and Coromina, L. Freixas and Fukami, S. and Fukazawa, Y. and Fukui, Y. and Gaggero, D. and Galanti, G. and Gammaldi, V. and Garcia, E. and Garczarczyk, M. and Gascon, D. and Gaug, M. and Gent, A. and Ghalumyan, A. and Ghirlanda, G. and Gianotti, F. and Giarrusso, M. and Giavitto, G. and Giglietto, N. and Giordano, F. and Glicenstein, J. and Goldoni, P. and González, J. M. and Gourgouliatos, K. and Grabarczyk, T. and Grandi, P. and Granot, J. and Grasso, D. and Green, J. and Grube, J. and Gueta, O. and Gunji, S. and Halim, A. and Harvey, M. and Collado, T. Hassan and Hayashi, K. and Heller, M. and Cadena, S. Hernández and Hervet, O. and Hinton, J. and Hiroshima, N. and Hnatyk, B. and Hnatyk, R. and Hoffmann, D. and Hofmann, W. and Holder, J. and Horan, D. and Hörandel, J. and Horvath, P. and Hovatta, T. and Hrabovsky, M. and Hrupec, D. and Hughes, G. and Hütten, M. and Iarlori, M. and Inada, T. and Inoue, S. and Insolia, A. and Ionica, M. and Iori, M. and Jacquemont, M. and Jamrozy, M. and Janecek, P. and Martínez, I. Jiménez and Jin, W. and Jung-Richardt, I. and Jurysek, J. and Kaaret, P. and Karas, V. and Karkar, S. and Kawanaka, N. and Kerszberg, D. and Khélifi, B. and Kissmann, R. and Knödlseder, J. and Kobayashi, Y. and Kohri, K. and Komin, N. and Kong, A. and Kosack, K. and Kubo, H. and Palombara, N. La and Lamanna, G. and Lang, R. G. and Lapington, J. and Laporte, P. and Lefaucheur, J. and Lemoine-Goumard, M. and Lenain, J. and Leone, F. and Leto, G. and Leuschner, F. and Lindfors, E. and Lloyd, S. and Lohse, T. and Lombardi, S. and Longo, F. and Lopez, A. and López, M. and López-Coto, R. and Loporchio, S. and Lucarelli, F. and Luque-Escamilla, P. L. and Lyard, E. and Maggio, C. and Majczyna, A. and Makariev, M. and Mallamaci, M. and Mandat, D. and Maneva, G. and Manganaro, M. and Manicò, G. and Marcowith, A. and Marculewicz, M. and Markoff, S. and Marquez, P. and Martí, J. and Martinez, O. and Martínez, M. and Martínez, G. and Martínez-Huerta, H. and Maurin, G. and Mazin, D. and Mbarubucyeye, J. D. and Miranda, D. Medina and Meyer, M. and Micanovic, S. and Miener, T. and Minev, M. and Miranda, J. M. and Mitchell, A. and Mizuno, T. and Mode, B. and Moderski, R. and Mohrmann, L. and Molina, E. and Montaruli, T. and Moralejo, A. and Merino, J. Morales and Morcuende-Parrilla, D. and Morselli, A. and Mukherjee, R. and Mundell, C. and Murach, T. and Muraishi, H. and Nagai, A. and Nakamori, T. and Nemmen, R. and Niemiec, J. and Nieto, D. and Nievas, M. and Nikolajuk, M. and Nishijima, K. and Noda, K. and Nosek, D. and Nozaki, S. and O'Brien, P. and Ohira, Y. and Ohishi, M. and Oka, T. and Ong, R. A. and Orienti, M. and Orito, R. and Orlandini, M. and Orlando, E. and Osborne, J. P. and Ostrowski, M. and Oya, I. and Pagliaro, A. and Palatka, M. and Paneque, D. and Pantaleo, F. R. and Paredes, J. M. and Parmiggiani, N. and Patricelli, B. and Pavletić, L. and Pe'er, A. and Pech, M. and Pecimotika, M. and Peresano, M. and Persic, M. and Petruk, O. and Pfrang, K. and Piatteli, P. and Pietropaolo, E. and Pillera, R. and Pilszyk, B. and Pimentel, D. and Pintore, F. and Pita, S. and Pohl, M. and Poireau, V. and Polo, M. and Prado, R. R. and Prast, J. and Principe, G. and Produit, N. and Prokoph, H. and Prouza, M. and Przybilski, H. and Pueschel, E. and Pühlhofer, G. and Pumo, M. L. and Punch, M. and Queiroz, F. and Quirrenbach, A. and Rando, R. and Razzaque, S. and Rebert, E. and Recchia, S. and Reichherzer, P. and Reimer, O. and Reimer, A. and Renier, Y. and Reposeur, T. and Rhode, W. and Ribeiro, D. and Ribó, M. and Richtler, T. and Rico, J. and Rieger, F. and Rizi, V. and Rodriguez, J. and Fernandez, G. Rodriguez and Ramirez, J. C. Rodriguez and Vázquez, J. J. Rodríguez and Romano, P. and Romeo, G. and Roncadelli, M. and Rosado, J. and Leon, A. Rosales de and Rowell, G. and Rudak, B. and Rujopakarn, W. and Russo, F. and Sadeh, I. and Saha, L. and Saito, T. and Greus, F. Salesa and Sanchez, D. and Sánchez-Conde, M. and Sangiorgi, P. and Sano, H. and Santander, M. and Santos, E. M. and Sanuy, A. and Sarkar, S. and Saturni, F. G. and Sawangwit, U. and Scherer, A. and Schleicher, B. and Schovanek, P. and Schussler, F. and Schwanke, U. and Sciacca, E. and Scuderi, S. and Arroyo, M. Seglar and Sergijenko, O. and Servillat, M. and Seweryn, K. and Shalchi, A. and Sharma, P. and Shellard, R. C. and Siejkowski, H. and Sinha, A. and Sliusar, V. and Slowikowska, A. and Sokolenko, A. and Sol, H. and Specovius, A. and Spencer, S. and Spiga, D. and Stamerra, A. and Stanič, S. and Starling, R. and Stolarczyk, T. and Straumann, U. and Strišković, J. and Suda, Y. and Świerk, P. and Tagliaferri, G. and Takahashi, H. and Takahashi, M. and Tavecchio, F. and Taylor, L. and Tejedor, L. A. and Temnikov, P. and Terrier, R. and Terzic, T. and Testa, V. and Tian, W. and Tibaldo, L. and Tonev, D. and Torres, D. F. and Torresi, E. and Tosti, L. and Tothill, N. and Tovmassian, G. and Travnicek, P. and Truzzi, S. and Tuossenel, F. and Umana, G. and Vacula, M. and Vagelli, V. and Valentino, M. and Vallage, B. and Vallania, P. and Eldik, C. van and Varner, G. S. and Vassiliev, V. and Acosta, M. Vázquez and Vecchi, M. and Veh, J. and Vercellone, S. and Vergani, S. and Verguilov, V. and Vettolani, G. P. and Viana, A. and Vigorito, C. F. and Vitale, V. and Vorobiov, S. and Vovk, I. and Vuillaume, T. and Wagner, S. J. and Walter, R. and Watson, J. and White, M. and White, R. and Wiemann, R. and Wierzcholska, A. and Will, M. and Williams, D. A. and Wischnewski, R. and Wolter, A. and Yamazaki, R. and Yanagita, S. and Yang, L. and Yoshikoshi, T. and Zacharias, M. and Zaharijas, G. and Zaric, D. and Zavrtanik, M. and Zavrtanik, D. and Zdziarski, A. A. and Zech, A. and Zechlin, H. and Zhdanov, V. I. and Živec, M.},
	urldate = {2023-09-19},
	date = {2021-02},
}

@article{acciari_optical_2020,
	title = {Optical intensity interferometry observations using the {MAGIC} Imaging Atmospheric Cherenkov Telescopes},
	volume = {491},
	issn = {0035-8711},
	url = {https://doi.org/10.1093/mnras/stz3171},
	doi = {10.1093/mnras/stz3171},
	abstract = {Imaging Atmospheric Cherenkov Telescopes ({IACTs}) currently in operation feature large mirrors and order of 1 ns time response to signals of a few photo-electrons produced by optical photons. This means that they are ideally suited for optical interferometry observations. Thanks to their sensitivity to visible wavelengths and long baselines optical intensity interferometry with {IACTs} allows reaching angular resolutions of tens to microarcseconds. We have installed a simple optical setup on top of the cameras of the two 17 m diameter Major Atmospheric Gamma-Ray Imaging Cherenkov ({MAGIC}) {IACTs} and observed coherent fluctuations in the photon intensity measured at the two telescopes for three different stars. The sensitivity is roughly 10 times better than that achieved in the 1970s with the Narrabri interferometer.},
	pages = {1540--1547},
	number = {2},
	journaltitle = {Monthly Notices of the Royal Astronomical Society},
	shortjournal = {Monthly Notices of the Royal Astronomical Society},
	author = {Acciari, V A and Bernardos, M I and Colombo, E and Contreras, J L and Cortina, J and De Angelis, A and Delgado, C and Díaz, C and Fink, D and Mariotti, M and Mangano, S and Mirzoyan, R and Polo, M and Schweizer, T and Will, M},
	urldate = {2023-09-19},
	date = {2020-01-11},
}

@article{abeysekara_demonstration_2020,
	title = {Demonstration of stellar intensity interferometry with the four {VERITAS} telescopes},
	volume = {4},
	issn = {2397-3366},
	url = {https://www.nature.com/articles/s41550-020-1143-y},
	doi = {10.1038/s41550-020-1143-y},
	abstract = {High angular resolution observations at optical wavelengths provide valuable insights into stellar astrophysics1,2, and enable direct measurements of fundamental stellar parameters3,4 and the probing of stellar atmospheres, circumstellar disks5, the elongation of rapidly rotating stars6 and the pulsations of Cepheid variable stars7. The angular size of most stars is of the order of one milliarcsecond or less, and to spatially resolve stellar disks and features at this scale requires an optical interferometer using an array of telescopes with baselines on the order of hundreds of metres. We report on the implementation of a stellar intensity interferometry system developed for the four {VERITAS} imaging atmospheric Cherenkov telescopes. The system was used to measure the angular diameter of the two sub-milliarcsecond stars β Canis Majoris and ϵ Orionis with a precision of greater than 5\%. The system uses an offline approach in which starlight intensity fluctuations that are recorded at each telescope are correlated post observation. The technique can be readily scaled onto tens to hundreds of telescopes, providing a capability that has proven technically challenging to the current generation of optical amplitude interferometry observatories. This work demonstrates the feasibility of performing astrophysical measurements using imaging atmospheric Cherenkov telescope arrays as intensity interferometers and shows the promise for integrating an intensity interferometry system within future observatories such as the Cherenkov Telescope Array.},
	pages = {1164--1169},
	number = {12},
	journaltitle = {Nature Astronomy},
	shortjournal = {Nat Astron},
	author = {Abeysekara, A. U. and Benbow, W. and Brill, A. and Buckley, J. H. and Christiansen, J. L. and Chromey, A. J. and Daniel, M. K. and Davis, J. and Falcone, A. and Feng, Q. and Finley, J. P. and Fortson, L. and Furniss, A. and Gent, A. and Giuri, C. and Gueta, O. and Hanna, D. and Hassan, T. and Hervet, O. and Holder, J. and Hughes, G. and Humensky, T. B. and Kaaret, P. and Kertzman, M. and Kieda, D. and Krennrich, F. and Kumar, S. and {LeBohec}, T. and Lin, T. T. Y. and Lundy, M. and Maier, G. and Matthews, N. and Moriarty, P. and Mukherjee, R. and Nievas-Rosillo, M. and O’Brien, S. and Ong, R. A. and Otte, A. N. and Pfrang, K. and Pohl, M. and Prado, R. R. and Pueschel, E. and Quinn, J. and Ragan, K. and Reynolds, P. T. and Ribeiro, D. and Richards, G. T. and Roache, E. and Ryan, J. L. and Santander, M. and Sembroski, G. H. and Wakely, S. P. and Weinstein, A. and Wilcox, P. and Williams, D. A. and Williamson, T. J.},
	urldate = {2023-09-19},
	date = {2020-12},
	keywords = {Astronomical instrumentation, Stars},
}

@article{delgado_intensity_2021,
	title = {Intensity interferometry with the {MAGIC} telescopes},
	volume = {{ICRC}2021},
	doi = {10.22323/1.395.0693},
	pages = {693},
	journaltitle = {{PoS}},
	author = {Delgado, Carlos and {others}},
	date = {2021},
}

@article{alom_state---art_2019,
	title = {A State-of-the-Art Survey on Deep Learning Theory and Architectures},
	volume = {8},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/8/3/292},
	doi = {10.3390/electronics8030292},
	abstract = {In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning ({DL}), starting with the Deep Neural Network ({DNN}). The survey goes on to cover Convolutional Neural Network ({CNN}), Recurrent Neural Network ({RNN}), including Long Short-Term Memory ({LSTM}) and Gated Recurrent Units ({GRU}), Auto-Encoder ({AE}), Deep Belief Network ({DBN}), Generative Adversarial Network ({GAN}), and Deep Reinforcement Learning ({DRL}). Additionally, we have discussed recent developments, such as advanced variant {DL} techniques based on these {DL} approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, {DL} approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, {SDKs}, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on {DL} using neural networks and a survey on Reinforcement Learning ({RL}). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.},
	pages = {292},
	number = {3},
	journaltitle = {Electronics},
	author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Chris and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Hasan, Mahmudul and Van Essen, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
	urldate = {2023-09-19},
	date = {2019-03},
	keywords = {auto-encoder ({AE}), convolutional neural network ({CNN}), deep belief network ({DBN}), deep learning, deep reinforcement learning ({DRL}), generative adversarial network ({GAN}), recurrent neural network ({RNN}), restricted Boltzmann machine ({RBM}), transfer learning},
}

@article{kim_enhancement_2022,
	title = {Enhancement of Partially Coherent Diffractive Images Using Generative Adversarial Network},
	volume = {3},
	issn = {2673-2688},
	url = {https://www.mdpi.com/2673-2688/3/2/17},
	doi = {10.3390/ai3020017},
	abstract = {We present a deep learning-based generative model for the enhancement of partially coherent diffractive images. In lensless coherent diffractive imaging, a highly coherent X-ray illumination is required to image an object at high resolution. Non-ideal experimental conditions result in a partially coherent X-ray illumination, lead to imperfections of coherent diffractive images recorded on a detector, and ultimately limit the capability of lensless coherent diffractive imaging. The previous approaches, relying on the coherence property of illumination, require preliminary experiments or expensive computations. In this article, we propose a generative adversarial network ({GAN}) model to enhance the visibility of fringes in partially coherent diffractive images. Unlike previous approaches, the model is trained to restore the latent sharp features from blurred input images without finding coherence properties of illumination. We demonstrate that the {GAN} model performs well with both coherent diffractive imaging and ptychography. It can be applied to a wide range of imaging techniques relying on phase retrieval of coherent diffraction patterns.},
	pages = {274--284},
	number = {2},
	journaltitle = {{AI}},
	author = {Kim, Jong Woo and Messerschmidt, Marc and Graves, William S.},
	urldate = {2023-09-19},
	date = {2022-06},
	keywords = {coherent diffractive imaging, {GAN} (generative adversarial network), partial coherence, phase retrieval, ptychography},
}

@misc{goodfellow_generative_2014,
	title = {Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	publisher = {{arXiv}},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	urldate = {2023-09-19},
	date = {2014-06-10},
	doi = {10.48550/arXiv.1406.2661},
	eprinttype = {arxiv},
	eprint = {1406.2661 [cs, stat]},
	note = {Issue: {arXiv}:1406.2661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{isola_image--image_2018,
	title = {Image-to-Image Translation with Conditional Adversarial Networks},
	url = {http://arxiv.org/abs/1611.07004},
	abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
	publisher = {{arXiv}},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	urldate = {2023-09-19},
	date = {2018-11-26},
	doi = {10.48550/arXiv.1611.07004},
	eprinttype = {arxiv},
	eprint = {1611.07004 [cs]},
	note = {Issue: {arXiv}:1611.07004},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@book{brown_intensity_1974,
	location = {London, New York},
	title = {The intensity interferometer: its application to astronomy},
	isbn = {978-0-470-10797-3},
	shorttitle = {The intensity interferometer},
	pagetotal = {184},
	publisher = {Taylor \& Francis; Halsted Press},
	author = {Brown, R. Hanbury},
	date = {1974},
	keywords = {Astronomy, Interferometers},
}

@article{aleksic_major_2016,
	title = {The major upgrade of the {MAGIC} telescopes, Part {II}: A performance study using observations of the Crab Nebula},
	volume = {72},
	issn = {0927-6505},
	url = {https://www.sciencedirect.com/science/article/pii/S0927650515000316},
	doi = {10.1016/j.astropartphys.2015.02.005},
	shorttitle = {The major upgrade of the {MAGIC} telescopes, Part {II}},
	abstract = {{MAGIC} is a system of two Imaging Atmospheric Cherenkov Telescopes located in the Canary island of La Palma, Spain. During summer 2011 and 2012 it underwent a series of upgrades, involving the exchange of the {MAGIC}-I camera and its trigger system, as well as the upgrade of the readout system of both telescopes. We use observations of the Crab Nebula taken at low and medium zenith angles to assess the key performance parameters of the {MAGIC} stereo system. For low zenith angle observations, the standard trigger threshold of the {MAGIC} telescopes is ∼ 50 {GeV}. The integral sensitivity for point-like sources with Crab Nebula-like spectrum above 220GeV is (0.66 ± 0.03)\% of Crab Nebula flux in 50h of observations. The angular resolution, defined as the σ of a 2-dimensional Gaussian distribution, at those energies is ≲ 0.07°, while the energy resolution is 16\%. We also re-evaluate the effect of the systematic uncertainty on the data taken with the {MAGIC} telescopes after the upgrade. We estimate that the systematic uncertainties can be divided in the following components: {\textbackslash}textless 15\% in energy scale, 11\%–18\% in flux normalization and ± 0.15 for the energy spectrum power-law slope.},
	pages = {76--94},
	journaltitle = {Astroparticle Physics},
	shortjournal = {Astroparticle Physics},
	author = {Aleksić, J. and Ansoldi, S. and Antonelli, L. A. and Antoranz, P. and Babic, A. and Bangale, P. and Barceló, M. and Barrio, J. A. and Becerra González, J. and Bednarek, W. and Bernardini, E. and Biasuzzi, B. and Biland, A. and Bitossi, M. and Blanch, O. and Bonnefoy, S. and Bonnoli, G. and Borracci, F. and Bretz, T. and Carmona, E. and Carosi, A. and Cecchi, R. and Colin, P. and Colombo, E. and Contreras, J. L. and Corti, D. and Cortina, J. and Covino, S. and Da Vela, P. and Dazzi, F. and De Angelis, A. and De Caneva, G. and De Lotto, B. and de Oña Wilhelmi, E. and Delgado Mendez, C. and Dettlaff, A. and Dominis Prester, D. and Dorner, D. and Doro, M. and Einecke, S. and Eisenacher, D. and Elsaesser, D. and Fidalgo, D. and Fink, D. and Fonseca, M. V. and Font, L. and Frantzen, K. and Fruck, C. and Galindo, D. and García López, R. J. and Garczarczyk, M. and Garrido Terrats, D. and Gaug, M. and Giavitto, G. and Godinović, N. and González Muñoz, A. and Gozzini, S. R. and Haberer, W. and Hadasch, D. and Hanabata, Y. and Hayashida, M. and Herrera, J. and Hildebrand, D. and Hose, J. and Hrupec, D. and Idec, W. and Illa, J. M. and Kadenius, V. and Kellermann, H. and Knoetig, M. L. and Kodani, K. and Konno, Y. and Krause, J. and Kubo, H. and Kushida, J. and La Barbera, A. and Lelas, D. and Lemus, J. L. and Lewandowska, N. and Lindfors, E. and Lombardi, S. and Longo, F. and López, M. and López-Coto, R. and López-Oramas, A. and Lorca, A. and Lorenz, E. and Lozano, I. and Makariev, M. and Mallot, K. and Maneva, G. and Mankuzhiyil, N. and Mannheim, K. and Maraschi, L. and Marcote, B. and Mariotti, M. and Martínez, M. and Mazin, D. and Menzel, U. and Miranda, J. M. and Mirzoyan, R. and Moralejo, A. and Munar-Adrover, P. and Nakajima, D. and Negrello, M. and Neustroev, V. and Niedzwiecki, A. and Nilsson, K. and Nishijima, K. and Noda, K. and Orito, R. and Overkemping, A. and Paiano, S. and Palatiello, M. and Paneque, D. and Paoletti, R. and Paredes, J. M. and Paredes-Fortuny, X. and Persic, M. and Poutanen, J. and Prada Moroni, P. G. and Prandini, E. and Puljak, I. and Reinthal, R. and Rhode, W. and Ribó, M. and Rico, J. and Rodriguez Garcia, J. and Rügamer, S. and Saito, T. and Saito, K. and Satalecka, K. and Scalzotto, V. and Scapin, V. and Schultz, C. and Schlammer, J. and Schmidl, S. and Schweizer, T. and Shore, S. N. and Sillanpää, A. and Sitarek, J. and Snidaric, I. and Sobczynska, D. and Spanier, F. and Stamerra, A. and Steinbring, T. and Storz, J. and Strzys, M. and Takalo, L. and Takami, H. and Tavecchio, F. and Tejedor, L. A. and Temnikov, P. and Terzić, T. and Tescaro, D. and Teshima, M. and Thaele, J. and Tibolla, O. and Torres, D. F. and Toyama, T. and Treves, A. and Vogler, P. and Wetteskind, H. and Will, M. and Zanin, R.},
	urldate = {2023-09-30},
	date = {2016-01-01},
	keywords = {Cherenkov telescopes, Crab Nebula, Gamma-ray astronomy},
}

@misc{mirza_conditional_2014,
	title = {Conditional Generative Adversarial Nets},
	url = {http://arxiv.org/abs/1411.1784},
	abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate {MNIST} digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
	publisher = {{arXiv}},
	author = {Mirza, Mehdi and Osindero, Simon},
	urldate = {2023-09-30},
	date = {2014-11-06},
	doi = {10.48550/arXiv.1411.1784},
	eprinttype = {arxiv},
	eprint = {1411.1784 [cs, stat]},
	note = {Issue: {arXiv}:1411.1784},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
}

@misc{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	publisher = {{arXiv}},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2023-09-30},
	date = {2015-05-18},
	doi = {10.48550/arXiv.1505.04597},
	eprinttype = {arxiv},
	eprint = {1505.04597 [cs]},
	note = {Issue: {arXiv}:1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{brown_lxxiv_1954,
	title = {{LXXIV}. A new type of interferometer for use in radio astronomy},
	volume = {45},
	issn = {1941-5982},
	url = {https://www.tandfonline.com/doi/citedby/10.1080/14786440708520475},
	doi = {10.1080/14786440708520475},
	pages = {663--682},
	number = {366},
	journaltitle = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
	author = {Brown, R. Hanbury and Twiss, R.q.},
	urldate = {2023-10-10},
	date = {1954-07},
	note = {Publisher: Taylor \& Francis},
}

@misc{saha_theory_2020,
	title = {The theory of intensity interferometry revisited},
	url = {http://arxiv.org/abs/2009.07284},
	doi = {10.48550/arXiv.2009.07284},
	abstract = {With the current revival of interest in astronomical intensity interferometry, it is interesting to revisit the associated theory, which was developed in the 1950s and 1960s. This paper argues that intensity interferometry can be understood as an extension of Fraunhofer diffraction to incoherent light. Interference patterns are still produced, but they are speckle-like and transient, changing on a time scale of \$1/{\textbackslash}Delta{\textbackslash}nu\$ (where \${\textbackslash}Delta{\textbackslash}nu\$ is the frequency bandwidth) known as the coherence time. Bright fringes average less than one photon per coherence time, hence fringes change before they can be observed. But very occasionally, two or even more photons may be detected from an interference pattern within a coherence time. These rare coincident photons provide information about the underlying transient interference pattern, and hence about the source brightness distribution. Thinking in terms of transient sub-photon interference patterns makes it easy to see why intensity interferometry will have large optical-path tolerance, and be immune to atmospheric seeing. The unusual signal-to-noise properties also become evident. We illustrate the unobservable but conceptually useful transient interference patterns, and their observable correlation signal, with three simulated examples: (i) an elongated source like Achernar, (ii) a three-star system like Algol, and (iii) a crescent source that roughly mimics an exoplanet transit or perhaps the M87 black hole environment. Of these, (i) and (ii) are good targets for currently-planned setups, while (iii) is interesting to think about for the longer term.},
	number = {{arXiv}:2009.07284},
	publisher = {{arXiv}},
	author = {Saha, Prasenjit},
	urldate = {2023-10-10},
	date = {2020-09-15},
	eprinttype = {arxiv},
	eprint = {2009.07284 [astro-ph]},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {arXiv Fulltext PDF:/home/yuri/Zotero/storage/CJBS8BJU/Saha - 2020 - The theory of intensity interferometry revisited.pdf:application/pdf;arXiv.org Snapshot:/home/yuri/Zotero/storage/3VVTEMZJ/2009.html:text/html},
}

@book{murphy_probabilistic_2022,
	location = {Cambridge, Massachusetts London, England},
	title = {Probabilistic machine learning: an introduction},
	isbn = {978-0-262-04682-4},
	series = {Adaptive computation and machine learning},
	shorttitle = {Probabilistic machine learning},
	abstract = {"This book provides a detailed and up-to-date coverage of machine learning. It is unique in that it unifies approaches based on deep learning with approaches based on probabilistic modeling and inference. It provides mathematical background (e.g. linear algebra, optimization), basic topics (e.g., linear and logistic regression, deep neural networks), as well as more advanced topics (e.g., Gaussian processes). It provides a perfect introduction for people who want to understand cutting edge work in top machine learning conferences such as {NeurIPS}, {ICML} and {ICLR}"--},
	pagetotal = {826},
	publisher = {The {MIT} Press},
	author = {Murphy, Kevin P.},
	date = {2022},
	file = {Table of Contents PDF:/home/yuri/Zotero/storage/3LIVCI36/Murphy - 2022 - Probabilistic machine learning an introduction.pdf:application/pdf},
}

@book{prince_understanding_2023,
	location = {Cambridge, Massachusetts},
	title = {Understanding deep learning},
	isbn = {978-0-262-04864-4},
	abstract = {"This book covers modern deep learning and tackles supervised learning, model architecture, unsupervised learning, and deep reinforcement learning"-- Provided by publisher},
	publisher = {The {MIT} Press},
	author = {Prince, Simon J. D.},
	date = {2023},
	note = {{OCLC}: 1372277824},
}

@software{isola_pix2pix_2023,
	title = {pix2pix},
	url = {https://github.com/phillipi/pix2pix},
	abstract = {Image-to-image translation with conditional adversarial nets},
	author = {Isola, Phillip},
	urldate = {2023-10-16},
	date = {2023-10-16},
	note = {original-date: 2016-11-16T22:48:50Z},
	keywords = {computer-graphics, computer-vision, dcgan, deep-learning, gan, generative-adversarial-network, image-generation, image-manipulation, image-to-image-translation, pix2pix},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: fundamental algorithms for scientific computing in Python},
	volume = {17},
	rights = {2020 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0686-2},
	doi = {10.1038/s41592-019-0686-2},
	shorttitle = {{SciPy} 1.0},
	abstract = {{SciPy} is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, {SciPy} has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of {SciPy} 1.0 and highlight some recent technical developments. This Perspective describes the development and capabilities of {SciPy} 1.0, an open source scientific computing library for the Python programming language.},
	pages = {261--272},
	number = {3},
	journaltitle = {Nature Methods},
	shortjournal = {Nat Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
	urldate = {2023-10-16},
	date = {2020-03},
	langid = {english},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {Biophysical chemistry, Computational biology and bioinformatics, Technology},
	file = {Full Text PDF:/home/yuri/Zotero/storage/SL5VQ6PD/Virtanen et al. - 2020 - SciPy 1.0 fundamental algorithms for scientific c.pdf:application/pdf},
}

@article{hunter_matplotlib_2007,
	title = {Matplotlib: A 2D Graphics Environment},
	volume = {9},
	issn = {1558-366X},
	url = {https://ieeexplore.ieee.org/document/4160265},
	doi = {10.1109/MCSE.2007.55},
	shorttitle = {Matplotlib},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems},
	pages = {90--95},
	number = {3},
	journaltitle = {Computing in Science \& Engineering},
	author = {Hunter, John D.},
	urldate = {2023-10-16},
	date = {2007-05},
	note = {Conference Name: Computing in Science \& Engineering},
	file = {IEEE Xplore Full Text PDF:/home/yuri/Zotero/storage/67LXSD6T/Hunter - 2007 - Matplotlib A 2D Graphics Environment.pdf:application/pdf},
}

@article{abadi_tensorflow_nodate,
	title = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
	author = {Abadi, Martın and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Mane, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Viegas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	langid = {english},
	file = {Abadi et al. - TensorFlow Large-Scale Machine Learning on Hetero.pdf:/home/yuri/Zotero/storage/NV7DNHFC/Abadi et al. - TensorFlow Large-Scale Machine Learning on Hetero.pdf:application/pdf},
}

@article{hayashida_optical_2015,
	title = {The Optical System for the Large Size Telescope of the Cherenkov Telescope Array},
	abstract = {The Large Size Telescope ({LST}) of the Cherenkov Telescope Array ({CTA}) is designed to achieve a threshold energy of 20 {GeV}. The {LST} optics is composed of one parabolic primary mirror 23 m in diameter and 28 m focal length. The reflector dish is segmented in 198 hexagonal, 1.51 m flat to flat mirrors. The total effective reflective area, taking into account the shadow of the mechanical structure, is about 368 m\${\textasciicircum}2\$. The mirrors have a sandwich structure consisting of a glass sheet of 2.7 mm thickness, aluminum honeycomb of 60 mm thickness, and another glass sheet on the rear, and have a total weight about 47 kg. The mirror surface is produced using a sputtering deposition technique to apply a 5-layer coating, and the mirrors reach a reflectivity of \${\textbackslash}sim\$94\% at peak. The mirror facets are actively aligned during operations by an active mirror control system, using actuators, {CMOS} cameras and a reference laser. Each mirror facet carries a {CMOS} camera, which measures the position of the light spot of the optical axis reference laser on the target of the telescope camera. The two actuators and the universal joint of each mirror facet are respectively fixed to three neighboring joints of the dish space frame, via specially designed interface plate.},
	author = {Hayashida, Michiyo and Noda, Koji and Teshima, M. and Barres de Almeida, Ulisses and Chikawa, Michiyuki and Cho, N. and Fukami, S. and Gadola, A. and Hanabata, Y. and Horns, D. and Jablonski, C. and Katagiri, Hideaki and Kagaya, M. and Ogino, M. and Okumura, Akira and Saito, Tadao and Stadler, R. and Steiner, S. and Straumann, U. and Consortium, for},
	date = {2015-08-30},
	file = {Full Text PDF:/home/yuri/Zotero/storage/7E96A8Q8/Hayashida et al. - 2015 - The Optical System for the Large Size Telescope of.pdf:application/pdf},
}
